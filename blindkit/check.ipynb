{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b3c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Servo moved to 90¬∞\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "ESP32_IP = \"http://192.168.204.171\"  # Replace with your ESP32-CAM IP\n",
    "\n",
    "# === Test Camera Feed ===\n",
    "def check_camera():\n",
    "    url = f\"{ESP32_IP}/cam-hi.jpg\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(\"test_image.jpg\", \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(\"‚úÖ Camera working! Image saved as test_image.jpg\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to get camera feed\")\n",
    "\n",
    "# === Test Servo Movement ===\n",
    "def move_servo(angle):\n",
    "    url = f\"{ESP32_IP}/servo_angle?value={angle}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ Servo moved to {angle}¬∞\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to move servo\")\n",
    "\n",
    "# === Test Ultrasonic Distance (if endpoint is available) ===\n",
    "def check_distance():\n",
    "    url = f\"{ESP32_IP}/distance\"  # Only if you added this endpoint in ESP32 code\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"üìè Distance: {response.text} cm\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to get distance\")\n",
    "\n",
    "move_servo(90)     # Move servo to 90 degrees\n",
    " # Test ultrasonic (if available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b774463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face, 23.7ms\n",
      "Speed: 2.5ms preprocess, 23.7ms inference, 42.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.6ms\n",
      "Speed: 2.2ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.9ms\n",
      "Speed: 2.0ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.7ms\n",
      "Speed: 2.0ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 18.6ms\n",
      "Speed: 3.0ms preprocess, 18.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 18.4ms\n",
      "Speed: 1.0ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 18.1ms\n",
      "Speed: 1.3ms preprocess, 18.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.1ms\n",
      "Speed: 2.5ms preprocess, 15.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 17.3ms\n",
      "Speed: 2.2ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.2ms\n",
      "Speed: 1.5ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.9ms\n",
      "Speed: 2.1ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.2ms\n",
      "Speed: 2.4ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.1ms\n",
      "Speed: 2.1ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.5ms\n",
      "Speed: 2.4ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.8ms\n",
      "Speed: 3.0ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.0ms\n",
      "Speed: 1.4ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 21.5ms\n",
      "Speed: 2.0ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 18.0ms\n",
      "Speed: 2.2ms preprocess, 18.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 18.7ms\n",
      "Speed: 1.0ms preprocess, 18.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.6ms\n",
      "Speed: 2.4ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 18.4ms\n",
      "Speed: 2.0ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 17.7ms\n",
      "Speed: 2.7ms preprocess, 17.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.7ms\n",
      "Speed: 2.3ms preprocess, 14.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.6ms\n",
      "Speed: 2.4ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.1ms\n",
      "Speed: 2.4ms preprocess, 14.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.4ms\n",
      "Speed: 1.3ms preprocess, 14.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.3ms\n",
      "Speed: 1.0ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.1ms\n",
      "Speed: 1.3ms preprocess, 15.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.9ms\n",
      "Speed: 2.6ms preprocess, 16.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.9ms\n",
      "Speed: 3.0ms preprocess, 13.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.2ms\n",
      "Speed: 1.2ms preprocess, 14.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.0ms\n",
      "Speed: 2.2ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 15.4ms\n",
      "Speed: 1.4ms preprocess, 15.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 14.0ms\n",
      "Speed: 2.1ms preprocess, 14.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 14.6ms\n",
      "Speed: 1.0ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 13.6ms\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 11.7ms\n",
      "Speed: 1.0ms preprocess, 11.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.2ms\n",
      "Speed: 1.4ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.2ms\n",
      "Speed: 1.0ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 13.4ms\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 14.7ms\n",
      "Speed: 1.0ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 12.8ms\n",
      "Speed: 1.1ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 16.8ms\n",
      "Speed: 2.2ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "#from modules.voice1 import speak_text\n",
    "\n",
    "# Emotion labels\n",
    "emotion_labels = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Sad\",\n",
    "    5: \"Surprise\",\n",
    "    6: \"Neutral\"\n",
    "}\n",
    "\n",
    "# Load ConvNeXt model\n",
    "def get_convnext(model_size='large', num_classes=7):\n",
    "    if model_size == 'tiny':\n",
    "        model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights)\n",
    "    elif model_size == 'small':\n",
    "        model = models.convnext_small(weights=models.ConvNeXt_Small_Weights)\n",
    "    elif model_size == 'base':\n",
    "        model = models.convnext_base(weights=models.ConvNeXt_Base_Weights)\n",
    "    else:\n",
    "        model = models.convnext_large(weights=models.ConvNeXt_Large_Weights)\n",
    "    model.classifier[2] = torch.nn.Linear(model.classifier[2].in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Load models\n",
    "face_detector = YOLO(r\".\\modules\\yolo_face_detection.pt\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "emotion_model = get_convnext(model_size='large', num_classes=7).to(device)\n",
    "emotion_model.load_state_dict(torch.load(r\".\\modules\\model_epoch_5.pth\", map_location=device))\n",
    "emotion_model.eval()\n",
    "\n",
    "# Preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Real-time prediction without storing predictions\n",
    "def live_emotion_prediction_realtime():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    last_emotion = None\n",
    "    speak_cooldown = 30  # Number of frames before speaking the same emotion again\n",
    "    frame_counter = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detector.predict(source=rgb_frame, save=False, conf=0.5)\n",
    "        detections = results[0].boxes.xyxy.cpu().numpy()\n",
    "        confidences = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "        for det, conf in zip(detections, confidences):\n",
    "            if conf < 0.5:\n",
    "                continue\n",
    "\n",
    "            xmin, ymin, xmax, ymax = map(int, det)\n",
    "            h, w, _ = frame.shape\n",
    "            x1, y1, x2, y2 = max(xmin, 0), max(ymin, 0), min(xmax, w - 1), min(ymax, h - 1)\n",
    "\n",
    "            face_img = rgb_frame[y1:y2, x1:x2]\n",
    "            if face_img.size == 0:\n",
    "                continue\n",
    "\n",
    "            face_pil = Image.fromarray(face_img)\n",
    "            input_tensor = preprocess(face_pil).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = emotion_model(input_tensor)\n",
    "                pred = int(logits.argmax(dim=1).item())\n",
    "                label = emotion_labels[pred]\n",
    "\n",
    "                # Speak only if emotion changes or cooldown passes\n",
    "                if label != last_emotion or frame_counter >= speak_cooldown:\n",
    "                    #speak_text(f\"{label}\")\n",
    "                    last_emotion = label\n",
    "                    frame_counter = 0\n",
    "\n",
    "                # Draw box and label\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.9, (0, 255, 0), 2)\n",
    "\n",
    "            break  # Only one face per frame\n",
    "\n",
    "        frame_counter += 1\n",
    "        cv2.imshow(\"Real-Time Emotion Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run it\n",
    "if __name__ == \"__main__\":\n",
    "    live_emotion_prediction_realtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b900026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing .\\dlib-19.22.99-cp310-cp310-win_amd64.whl\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.22.99\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib-19.22.99-cp310-cp310-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b44867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\vsrik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face_recognition) (8.1.8)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\vsrik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face_recognition) (19.22.99)\n",
      "Requirement already satisfied: numpy in c:\\users\\vsrik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face_recognition) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vsrik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face_recognition) (10.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vsrik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: face-recognition-models, face_recognition\n",
      "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1273ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∑ Capturing image from webcam...\n",
      "üé§ Please say your name...\n",
      "‚úÖ Image saved as: d:\\niit\\ml\\blindkit\\known image\\akka_20250415_182844.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'akka'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "# Dynamic Output Directory\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), \"known image\")\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# Load Face Detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_faces(frame):\n",
    "    \"\"\" Detect faces in a given frame using OpenCV Haar Cascade. \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=6, minSize=(40, 40))\n",
    "    return faces\n",
    "\n",
    "# def detect_faces(frame):\n",
    "#     \"\"\" Detect faces in a given frame using OpenCV Haar Cascade. \"\"\"\n",
    "#     frame_resized = cv2.resize(frame, (640, 480))  # Resize for consistent detection\n",
    "#     gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "#     gray = cv2.equalizeHist(gray)  # Improve contrast\n",
    "#     faces = face_cascade.detectMultiScale(\n",
    "#         gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "#     return faces\n",
    "\n",
    "def face_add():\n",
    "    \"\"\" Capture, detect faces, get a name, and save the image with the recognized name. \"\"\"\n",
    "    print(\"üì∑ Capturing image from webcam...\")\n",
    "\n",
    "    # Open webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Could not open webcam.\")\n",
    "        return None\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()  # Release the webcam\n",
    "\n",
    "    if not ret:\n",
    "        print(\"‚ùå Failed to capture image.\")\n",
    "        return None\n",
    "\n",
    "    # Detect faces\n",
    "    faces = detect_faces(frame)\n",
    "    if len(faces) == 0:\n",
    "        print(\"‚ö†Ô∏è No face detected! Try adjusting the camera angle or lighting.\")\n",
    "        return None\n",
    "\n",
    "    # Draw rectangles around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Get Name via Voice\n",
    "    print(\"üé§ Please say your name...\")\n",
    "    person_name = input(\"Couldn't detect name. Enter manually: \").strip()\n",
    "    if not person_name:\n",
    "        print(\"‚ùå No name provided! Image not saved.\")\n",
    "        return None\n",
    "\n",
    "    # Generate Unique File Name\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f\"{person_name}_{timestamp}.jpg\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, file_name)\n",
    "\n",
    "    # Save the image\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    print(f\"‚úÖ Image saved as: {output_path}\")\n",
    "\n",
    "    # Store name in a text |file (for reference)\n",
    "    with open(os.path.join(OUTPUT_DIR, \"face_log.txt\"), \"a\") as f:\n",
    "        f.write(f\"{person_name}, {output_path}\\n\")\n",
    "\n",
    "    return person_name  # Return the detected name for further use\n",
    "face_add()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7386217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing frames from webcam and recognizing faces...\n",
      "Frame 1: Recognized - ['akka_20250415_182844', 'Unknown']\n",
      "Frame 2: Recognized - ['akka_20250415_182844', 'sriks_20250415_182753']\n",
      "Frame 3: Recognized - ['akka_20250415_182844']\n",
      "Most frequently recognized face: akka_20250415_182844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Most frequently recognized face: akka_20250415_182844'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import face_recognition\n",
    "from statistics import mode, StatisticsError\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def load_known_faces():\n",
    "    #change path where knownface is stores\n",
    "    known_faces_dir = r\".\\known image\"\n",
    "    known_encodings = []\n",
    "    known_names = []\n",
    "    for filename in os.listdir(known_faces_dir):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            image_path = os.path.join(known_faces_dir, filename)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_encodings.append(encodings[0])\n",
    "                known_names.append(os.path.splitext(filename)[0])\n",
    "    return known_encodings, known_names\n",
    "\n",
    "def recognize_faces(image_path, known_encodings, known_names):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    encodings = face_recognition.face_encodings(image)\n",
    "    recognized_faces = []\n",
    "    for encoding in encodings:\n",
    "        results = face_recognition.compare_faces(known_encodings, encoding)\n",
    "        distances = face_recognition.face_distance(known_encodings, encoding)\n",
    "        if any(results):\n",
    "            best_match_index = distances.argmin()\n",
    "            recognized_faces.append(known_names[best_match_index])\n",
    "        else:\n",
    "            recognized_faces.append(\"Unknown\")\n",
    "    return recognized_faces\n",
    "\n",
    "def get_most_frequent_face_name(known_encodings, known_names, num_frames=3):\n",
    "    recognized_list = []\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return \"Camera error\"\n",
    "\n",
    "    print(\"Capturing frames from webcam and recognizing faces...\")\n",
    "    for i in range(num_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Frame {i+1}: Error capturing frame from webcam.\")\n",
    "            continue\n",
    "\n",
    "        temp_path = f\"temp_frame_{i}.jpg\"\n",
    "        cv2.imwrite(temp_path, frame)\n",
    "\n",
    "        faces = recognize_faces(temp_path, known_encodings, known_names)\n",
    "        print(f\"Frame {i+1}: Recognized - {faces}\")\n",
    "        recognized_list.extend(faces)\n",
    "        time.sleep(1)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not recognized_list:\n",
    "        return \"No faces detected.\"\n",
    "\n",
    "    try:\n",
    "        most_common = Counter(recognized_list).most_common(1)[0][0]\n",
    "        return f\"Most frequently recognized face: {most_common}\"\n",
    "    except StatisticsError:\n",
    "        return \"No unique most frequent face (tie or none recognized).\"\n",
    "\n",
    "\n",
    "def facesd():\n",
    "    known_encodings, known_names = load_known_faces()\n",
    "    if not known_encodings:\n",
    "        print(\"No known faces loaded. Please add images to the 'known image' directory.\")\n",
    "        return\n",
    "\n",
    "    result = get_most_frequent_face_name(known_encodings, known_names)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "facesd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
